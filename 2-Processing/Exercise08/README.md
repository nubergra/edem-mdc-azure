# Azure Processing - Exercise 8: Simple pipeline in Data Factory

## **Objective**  

In this exercise, we will build a **simple pipeline** in **Azure Data Factory**, moving data between storage locations.  

## **Steps**  

1. **Create a pipeline** to copy data from **Azure Blob Storage** to another location. You can use the `holiday_songs.csv` or the customers data CSV from previous exercises or choose your own data. To simplify things, you could move the CSV from one Blob Storage container to another. You could also try to use ADLS instead and move files within folders in the container.
2. **Set up a trigger** to schedule pipeline execution or **manually trigger** the pipeline.
3. **Monitor the pipeline run** to ensure successful data movement.  

## **Resources**  

- ðŸ“Œ [Azure Portal](https://portal.azure.com)  
- ðŸ“– [Azure Data Factory Pipelines](https://learn.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities)  